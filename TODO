could calculate distance statistics while combining pairs.  what is a good way to report these numbers?  being able to write them to a file is nice too.

could probably move UnambiguousFilter to a --unambiguous switch on the combiner

pipelined job could save on creation of temp dir (writing to input-part-N) and writing final output files

is it possible to calculate distance stat numbers in separate mappers and combine into a single num?

possibly, parsing bowtie and splats could be combined into one job, by checking the number of columns in the input.  that would be a hack.  hadoop/java supports this natively via http://archive.cloudera.com/cdh/3/hadoop/api/org/apache/hadoop/mapreduce/lib/input/MultipleInputs.html

update README

easily tracking resource (CPU/memory) usage would be nice

generated docs

code comments
cli parameter help

weighted coverage

model-tidy, given multiple gff files, output one that's been cleaned up
  - detect and resolve duplicate IDs (by appending -N)
  - related features are grouped
  - invalid lines are removed
  - genes with no mRNA children are removed


init: foo
    TODO add virtualenv to odetta, or maybe just wget
    wget https://raw.github.com/pypa/virtualenv/master/virtualenv.py

    $(PYTHON) virtualenv.py venv
    detect shell and source appropriately
      source venv/bin/activate.csh

    setenv LD_LIBRARY_PATH /pseudospace1/buchanae/spatialindexlib/lib:$LD_LIBRARY_PATH

    ./venv/bin/nosetests-2.7 tests/


file bug with mrjob:
    if sort fails on unix (because of something like a full tmp dir) it will try again
    with piping (which is meant for windows compat.) but really it's just going to fail
    again.  also, a sort fail could mention sort-stderr or print out a useful message
